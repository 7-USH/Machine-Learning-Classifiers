{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "\n",
    "    def __init__(self,position_in_layer,is_output_neuron=False):\n",
    "        self.weights = []\n",
    "        self.inputs = []\n",
    "        self.output = None\n",
    "        self.updated_weights = []\n",
    "        self.is_output_neuron = is_output_neuron\n",
    "        self.delt = None\n",
    "        self.position_in_layer = position_in_layer\n",
    "    \n",
    "    def attach_to_output(self,neurons):\n",
    "        self.output_neurons = []\n",
    "        for n in neurons:\n",
    "            self.output_neurons.append(n)\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1+math.exp(-x))\n",
    "    \n",
    "    def init_weights(self,num_input):\n",
    "        for _ in range(num_input):\n",
    "            self.weights.append(random.uniform(0,1))\n",
    "\n",
    "    def predict(self,row):\n",
    "        self.inputs = []\n",
    "        activation = 0\n",
    "        for weight, feature in zip(self.weights,row):\n",
    "            self.inputs.append(feature)\n",
    "            activation = activation + weight * feature\n",
    "        self.output = self.sigmoid(activation)\n",
    "        return self.output\n",
    "    \n",
    "    def update_neuron(self):\n",
    "        self.weights = []\n",
    "        for new_weights in self.updated_weights:\n",
    "            self.weights.append(new_weights)\n",
    "\n",
    "    def calculate_update(self,learning_rate,target):\n",
    "        if self.is_output_neuron:\n",
    "            self.delta = (self.output - target) * self.output*(1-self.output)\n",
    "        else:\n",
    "            delta_sum = 0\n",
    "            cur_weights_index = self.position_in_layer\n",
    "            for output_neuron in self.output_neurons:\n",
    "                delta_sum = delta_sum + (output_neuron.delta * output_neuron.weights[cur_weights_index])\n",
    "            self.delta = delta_sum * self.output*(1-self.output)\n",
    "\n",
    "        self.updated_weights = []\n",
    "\n",
    "        for cur_weights,cur_input in zip(self.weights,self.inputs):\n",
    "            gradient = self.delta * cur_input\n",
    "            new_weight = cur_weights - learning_rate * gradient\n",
    "            self.updated_weights.append(new_weight)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \n",
    "    def __init__(self,num_neuron,is_output_layer = False):\n",
    "        self.is_output_layer = is_output_layer\n",
    "        self.neurons = []\n",
    "        for i in range(num_neuron):\n",
    "            neuron = Neuron(i,is_output_neuron=is_output_layer)\n",
    "            self.neurons.append(neuron)\n",
    "    \n",
    "    def attach(self,layer):\n",
    "        for in_neuron in self.neurons:\n",
    "            in_neuron.attach_to_output(layer.neurons)\n",
    "    \n",
    "    def init_layer(self,num_input):\n",
    "        for neuron in self.neurons:\n",
    "            neuron.init_weights(num_input)\n",
    "    \n",
    "    def predict(self,row):\n",
    "        activations = [neuron.predict(row) for neuron in self.neurons]\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron():\n",
    "    \n",
    "    def __init__(self,learning_rate = 0.01,num_iterations = 100):\n",
    "        self.layers = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.errors = []\n",
    "        self.loss = []\n",
    "    \n",
    "    def eta(self,x):\n",
    "        return np.maximum(x, 0.0000000001)\n",
    "\n",
    "    def entropy_loss(self, y, y_pred):\n",
    "        y_pred_inv = self.eta(1 - y_pred)\n",
    "        y_inv = self.eta(1 - y)\n",
    "        loss = -np.average(y*np.log(y_pred) +\n",
    "                           y_inv * np.log(y_pred_inv))\n",
    "        return loss\n",
    "\n",
    "    def add_output_layer(self,num_neuron):\n",
    "        self.layers.insert(0,Layer(num_neuron,is_output_layer=True))\n",
    "    \n",
    "    def add_hidden_layer(self,num_neuron):\n",
    "        hidden_layer = Layer(num_neuron)\n",
    "        hidden_layer.attach(self.layers[0])\n",
    "        self.layers.insert(0,hidden_layer)\n",
    "\n",
    "    def update_layers(self,target):\n",
    "        for layer in reversed(self.layers):\n",
    "            for neuron in layer.neurons:\n",
    "                neuron.calculate_update(self.learning_rate,target)\n",
    "        for layer in self.layers:\n",
    "            for neuron in layer.neurons:\n",
    "                neuron.update_neuron()\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_row,num_feature = X.shape\n",
    "        X = X.values.tolist()\n",
    "        self.layers[0].init_layer(num_feature)\n",
    "\n",
    "        for i in range(1,len(self.layers)):\n",
    "            num_input = len(self.layers[i-1].neurons)\n",
    "            self.layers[i].init_layer(num_input)\n",
    "        \n",
    "        for _ in range(self.num_iterations):\n",
    "            r_i = random.randint(0,num_row-1)\n",
    "            row = X[r_i]\n",
    "            y_pred = self.predict(row)\n",
    "            target = y[r_i]\n",
    "            self.update_layers(target)\n",
    "\n",
    "            if _ % 1000 == 0:\n",
    "                total_error = 0\n",
    "                for r_i in range(num_row):\n",
    "                    row = X[r_i]\n",
    "                    y_pred = self.predict(row)\n",
    "                    self.loss.append(self.entropy_loss(y[r_i][0],y_pred))\n",
    "                    error = (y[r_i][0]-y_pred)\n",
    "                    total_error = total_error + error ** 2\n",
    "                mean_error = total_error/num_row\n",
    "                print(f\"Iteration {_} with mean error = {mean_error}\")\n",
    "    \n",
    "    def predict(self,row):\n",
    "        activations = self.layers[0].predict(row)\n",
    "\n",
    "        for _ in range(1,len(self.layers)):\n",
    "            activations = self.layers[_].predict(activations)\n",
    "        \n",
    "        outputs = []\n",
    "\n",
    "        for activation in activations:\n",
    "            if activation >= 0.5:\n",
    "                outputs.append(1)\n",
    "            else:\n",
    "                outputs.append(0)\n",
    "        return outputs[0]          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart_disease.csv\")\n",
    "X_df = df.drop([\"condition\"], axis=1)\n",
    "X_pre = scaler.fit_transform(X_df)\n",
    "X = pd.DataFrame(X_pre, columns=df.columns[:-1])\n",
    "y = df[\"condition\"].values.reshape(X.shape[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 with mean error = 0.5569620253164557\n",
      "Iteration 1000 with mean error = 0.38396624472573837\n",
      "Iteration 2000 with mean error = 0.20253164556962025\n",
      "Iteration 3000 with mean error = 0.15611814345991562\n",
      "Iteration 4000 with mean error = 0.1350210970464135\n",
      "Iteration 5000 with mean error = 0.12658227848101267\n",
      "Iteration 6000 with mean error = 0.1350210970464135\n",
      "Iteration 7000 with mean error = 0.1350210970464135\n",
      "Iteration 8000 with mean error = 0.12236286919831224\n",
      "Iteration 9000 with mean error = 0.11814345991561181\n"
     ]
    }
   ],
   "source": [
    "clf = MultiLayerPerceptron(learning_rate=0.1, num_iterations=10000)\n",
    "clf.add_output_layer(num_neuron=1)\n",
    "clf.add_hidden_layer(num_neuron=3)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "     row = np.asarray(X_test)[i]\n",
    "     if clf.predict(row) == y_test[i]:\n",
    "          acc += 1\n",
    "print(acc/X_test.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
